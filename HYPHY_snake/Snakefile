from itertools import groupby
from itertools import (takewhile,repeat) #no longer needed 5.3.17
from Bio.Phylo.PAML import codeml
from Bio.Phylo.PAML.chi2 import cdf_chi2
from Bio.Align.Applications import MafftCommandline #no longer needed 5.3.17
from io import StringIO #no longer needed 5.3.17
from Bio import AlignIO #no longer needed 5.3.17
from Bio import SeqIO #no longer needed 5.3.17
import sys #no longer needed 5.3.17
import re
from scipy import stats

def fasta_iter(fasta_name):
    fh = open(fasta_name)
    faiter = (x[1] for x in groupby(fh, lambda line: line[0] == ">"))
    for header in faiter:
        headerStr = header.__next__()[1:].strip()#Entire line, add .split[0] for just first column
        seq = "".join(s.strip() for s in faiter.__next__())
        yield (headerStr, seq)
def stringSplitter(string,delimiter,avoid):
    finalString = ""
    numSpecialChar = 0
    for i in string:
        specialCharacterBool= (not i.isdigit() and not i.isalpha() and i!=avoid)
        if specialCharacterBool:
            numSpecialChar+=1
        else:
            if numSpecialChar > 0:
                finalString+=delimiter
            finalString+=i
            numSpecialChar = 0
    return finalString


SAMPLES, = glob_wildcards("{sample}.fasta")

rule final:
    input:expand("intermediate_files/all.pep.combined",sample=SAMPLES)

    # input:"test.fasta.fubar.csv"

rule cleanFasta:
    input:
        "{sample}.fasta"
    output:
        "intermediate_files/{sample}.clean"
    run:
        Trinity_bool = False
        signature = ""
        sample = input[0].split('.')[0]
        sequence_iterator = fasta_iter(input[0])
        fileLength = 0
        columnCountDict={}
        wordDict = {}
        rowMembers = 1
        fileLength = 0
        newDict = {}
        subString = ""
        # usableColumns = 0
        pattern = ""
        patternExists = True
        with open(output[0],"w") as out:
            for ff in sequence_iterator:

                headerStr, seq = ff
                trinity_identifiers = re.search("c"+"(.*)"+"_g"+"(.*)"+"_i",headerStr)
                if trinity_identifiers !=None:
                    Trinity_bool = True
                out.write(">"+headerStr+'\n')
                out.write(  seq +"\n")
                fileLength+=1
                splitHeader = re.split(r'[`\ =~!@#$%^&*()_+\[\]{};\'\\:"|<,./<>?]', headerStr)

                colNum = len(splitHeader)
                #NOTE issue no1 lies here
                try:
                    # print("thing>>>>>>>>>>>>>>>>>>>>>>>",len(splitHeader),splitHeader)
                    usableColumns = min(colNum, usableColumns)
                except:
                    # print("except>>>>>>>>>>>>>>>>>>>>>>>",len(splitHeader), splitHeader)
                    usableColumns = colNum

                # print("Usable columns",usableColumns)
                #FIXME issue no2 lies here, wordDict ends up empty

                for i in range(usableColumns):
                    try:
                        wordDict[i][splitHeader[i]] = True
                    except:
                        wordDict[i] = {}
                        wordDict[i][splitHeader[i]] = True
                    # print(wordDict.keys())
            #FIXME issue no3, signature also ends up blank, resulting from blank wordDict
            for i in range(usableColumns):
                if len(wordDict[i].keys()) == fileLength:
                    signature+="{unique_id}:"
                elif len(wordDict[i].keys()) == 1:
                    for j in wordDict[i].keys():
                        signature+=j + ":"
                else:
                    signature+="{isoform_id}:"
            # print(signature)
            signature = signature[:-1]

            # print(signature)
            # print(wordDict.keys())

        # print("Is this Trinity?",Trinity_bool)
        # print("^^^^^^^^^^^^^^^^SIGNATURE************>>>>>>>>>",signature)
        with open("headerPatterns.txt","a") as out:
            #NOTE
                #1. if trinity, write file
                #2. if unique_id, try writing file
                    #*** a. if only one isoform_id, write file
                    #*** b. otherwise, just unique_id will be used in next rule
            if Trinity_bool:
                out.write(sample+"\t"+"TRINITY\n")
            elif "{unique_id}" in signature:

                out.write(sample+"\t"+signature+"\n")

rule newHeaders:
    input:
        "intermediate_files/{sample}.clean"
    output:
        "intermediate_files/{sample}.new_headers"
    run:
        try:
            patternDict = {}
            with open("headerPatterns.txt") as f:
                for line in f:
                    row = line.strip().split()
                    patternDict[row[0]] = row[1]
            with open(output[0],"w") as out:
                pattern = patternDict[input[0].split('.')[0]]

                if "{unique_id}" in pattern:
                    if pattern.count("{isoform_id}") == 1:
                        pattern_list = pattern.split(":")
                        for i in range(len(pattern_list)):
                            if pattern_list[i] == "{isoform_id}":
                                isoform_pos =  i
                                continue
                            elif pattern_list[i] == "{unique_id}":
                                unique_pos =  i
                                continue

                sequence_iterator = fasta_iter(input[0])
                for ff in sequence_iterator:

                    headerStr, seq = ff
                    if pattern == "TRINITY":
                        trinity_identifiers = re.search("c"+"(.*)"+"_g"+"(.*)"+"_i",headerStr)
                        new_header = stringSplitter(headerStr.split()[0],"_","-")#[:trinity_identifiers.span()[1]+1]
                    if "{unique_id}" in pattern:
                        splitHeader = re.split(r'[`\ =~!@#$%^&*()_+\[\]{};\'\\:"|<,./<>?]', stringSplitter(headerStr,"_","-"))
                        if pattern.count("{isoform_id}") == 1:
                            new_header = splitHeader[unique_pos] + "___" + splitHeader[isoform_pos]
                        else:
                            new_header = splitHeader[unique_pos]
                    out.write( ">"+new_header+'\n')
                    out.write(seq+'\n')

        except:
            with open(output[0],"w") as out:

                sequence_iterator = fasta_iter(input[0])
                for ff in sequence_iterator:

                    headerStr, seq = ff
                    out.write( ">"+stringSplitter(headerStr,"_","-").split()[0] +'\n')
                    out.write(seq+'\n')

rule transdecoderLongIsoforms:
    input:
        "intermediate_files/{sample}.new_headers"
    output:
        "{sample}.new_headers.transdecoder_dir/longest_orfs.pep"
    conda:
        "envs/transdecoder.yaml"
    shell:
            "TransDecoder.LongOrfs -t {input}  -m 30"


rule transdecoderPredict:
    input:
        fastaFile="intermediate_files/{sample}.new_headers",LongOrfs="intermediate_files/{sample}.new_headers.transdecoder_dir/longest_orfs.pep"
    output:
        "intermediate_files/{sample}.new_headers.transdecoder.pep","intermediate_files/{sample}.new_headers.transdecoder.cds"
    conda:
        "envs/transdecoder.yaml"
    shell:
            "TransDecoder.Predict -t {input.fastaFile} --single_best_orf"

rule longestIsoformPep:
    input:
        "intermediate_files/{sample}.new_headers.transdecoder.pep"
    output:
        "intermediate_files/{sample}.longestIsoform.pep"
    run:
        patternDict = {}
        with open("headerPatterns.txt") as f:
            for line in f:
                row = line.strip().split()
                patternDict[row[0]] = row[1]
        try:
            pattern = patternDict[input[0].split('.')[0]]
        except:
            pattern = None
        # print(pattern)
        with open(output[0], "w") as out:

            longIsoform={}

            sequence_iterator = fasta_iter(input[0])
            sample = input[0].split('.')[0]
            for ff in sequence_iterator:

                headerStr, seq = ff

                # print("trinity_identifiers:",trinity_identifiers)
                if pattern =="TRINITY":
                    trinity_identifiers = re.search("c"+"(.*)"+"_g"+"(.*)"+"_i",headerStr)
                    # print("trinity_identifiers:",trinity_identifiers,"\n",headerStr)
                    # GeneID = headerStr[:trinity_identifiers.span()[1]].split("::")[1]
                    gene_header = headerStr.split("::")[1]
                    trinity_identifiers = re.search("c"+"(.*)"+"_g"+"(.*)"+"_i",gene_header)
                    GeneID = gene_header[:trinity_identifiers.span()[1]]
                else:
                    try:

                        GeneID=headerStr.split('___')[1].split('::')[0]
                    except:
                        reduced_header = stringSplitter(headerStr.split()[0].split("::")[0]+headerStr.split()[0].split("::")[1],"_","-")
                        out.write('>'+sample+"_"+reduced_header+'\n')
                        out.write(seq + '\n')
                        continue
                if GeneID not in longIsoform:
                    longIsoform[GeneID] = [len(seq),headerStr,seq]
                else:
                    if longIsoform[GeneID][0] < len(seq):
                        longIsoform[GeneID] = [len(seq),headerStr,seq]
            for i in longIsoform.keys():
                out.write('>'+sample+'_'+i+'\n')
                # out.write('>'+sample+'_'+longIsoform[i][1].split("::")[0]+'\n')
                out.write(longIsoform[i][2]+'\n')


rule longestIsoformCDS:
    input:
        "intermediate_files/{sample}.new_headers.transdecoder.cds"
    output:
        "intermediate_files/{sample}.longestIsoform.cds"
    run:
        patternDict = {}
        with open("headerPatterns.txt") as f:
            for line in f:
                row = line.strip().split()
                patternDict[row[0]] = row[1]
        try:
            pattern = patternDict[input[0].split('.')[0]]
        except:
            pattern = None
        with open(output[0], "w") as out:

            longIsoform={}

            sequence_iterator = fasta_iter(input[0])
            sample = input[0].split('.')[0]
            for ff in sequence_iterator:

                headerStr, seq = ff

                if pattern =="TRINITY":
                    trinity_identifiers = re.search("c"+"(.*)"+"_g"+"(.*)"+"_i",headerStr)
                    # GeneID = headerStr[:trinity_identifiers.span()[1]].split("::")[1]
                    gene_header = headerStr.split("::")[1]
                    trinity_identifiers = re.search("c"+"(.*)"+"_g"+"(.*)"+"_i",gene_header)
                    GeneID = gene_header[:trinity_identifiers.span()[1]]
                else:
                    try:

                        GeneID=headerStr.split('___')[1].split('::')[0]
                    except:
                        reduced_header = stringSplitter(headerStr.split()[0].split("::")[0]+headerStr.split()[0].split("::")[1],"_","-")
                        out.write('>'+sample+"_"+reduced_header+'\n')
                        out.write(seq + '\n')
                        continue
                if GeneID not in longIsoform:
                    longIsoform[GeneID] = [len(seq),headerStr,seq]
                else:
                    if longIsoform[GeneID][0] < len(seq):
                        longIsoform[GeneID] = [len(seq),headerStr,seq]
            for i in longIsoform.keys():
                out.write('>'+sample+'_'+i+'\n')
                # out.write('>'+sample+'_'+longIsoform[i][1].split("::")[0]+'\n')
                out.write(longIsoform[i][2]+'\n')
rule combine_pep_and_cds:
    input:
        pep=expand("intermediate_files/{sample}.longestIsoform.pep",sample=SAMPLES),
        cds=expand("intermediate_files/{sample}.longestIsoform.cds",sample=SAMPLES)
    output:
        "intermediate_files/all.pep.combined","intermediate_files/fusterID.txt","intermediate_files/all.cds.combined"

    run:
        fusterID = 1
        idDict = {}

        with open(output[1],"w") as id_out:
            with open(output[0] ,"w") as pep_out:
                for i in input.pep:
                    for line in open(i):
                        if ">" in line:
                            pep_out.write(">fusterID_"+str(fusterID)+"\n")
                            idDict[line.strip().strip(">")] = "fusterID_" + str(fusterID)
                            id_out.write("fusterID_"+str(fusterID) + "\t"+line.strip(">"))
                            fusterID+=1
                        else:
                            pep_out.write(line)
        with open(output[2],"w") as cds_out:

            for i in input.cds:
                for line in open(i):
                    if  ">" in line:
                        cds_out.write(">" + idDict[line.strip().strip(">")]+"\n")

                    else:
                        cds_out.write(line)

rule hyphy:
    input:
        tree="test.tree",
        align="test.fasta"
    output:
        "test.fasta.fubar.csv"
    shell:
        "(echo 1; echo 1;echo /home/usr/FUSTr/HYPHY_snake/{input.align}; echo /home/usr/FUSTr/HYPHY_snake/{input.tree}; echo 20;echo echo 5; echo 2000000; echo 1000000;echo 100;echo 0.5 )|HYPHYMP /home/usr/hyphy/res/TemplateBatchFiles/FUBAR.bf"




# (echo 1; echo 1;echo test.fasta; echo test.tree; echo 20;echo echo 5; echo 2000000; echo 1000000;echo 100;echo 0.5 )|HYPHYMP /home/usr/hyphy/res/TemplateBatchFiles/FUBAR.bf
# (echo 1; echo 1;echo /home/usr/HYPHY_snake/test.fasta; echo /home/usr/HYPHY_snake/test.tree; echo 20;echo echo 5; echo 2000000; echo 1000000;echo 100;echo 0.5 )|HYPHYMP /home/usr/hyphy/res/TemplateBatchFiles/FUBAR.bf

# (echo 1; echo 1;echo /home/usr/FUSTr/HYPHY_snake/test.fasta; echo /home/usr/FUSTr/HYPHY_snake/test.tree; echo 20;echo echo 5; echo 2000000; echo 1000000;echo 100;echo 0.5 )|HYPHYMP /home/usr/hyphy/res/TemplateBatchFiles/FUBAR.bf
